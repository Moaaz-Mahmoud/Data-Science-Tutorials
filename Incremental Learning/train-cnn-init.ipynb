{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 15:01:29.207743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[157, 181, 201], [156, 181, 201], [157, 182,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[85, 91, 104], [87, 95, 108], [82, 94, 106],...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[173, 188, 191], [172, 187, 190], [177, 192,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[236, 240, 240], [212, 216, 217], [199, 202,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[[197, 199, 200], [197, 199, 200], [197, 199,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[[163, 173, 183], [165, 175, 185], [166, 174,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[[242, 251, 248], [242, 251, 248], [240, 249,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[[196, 193, 188], [196, 193, 188], [196, 193,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[[237, 209, 192], [237, 209, 192], [233, 205,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[[11, 6, 12], [11, 7, 13], [11, 7, 13], [8, 7...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[[103, 103, 117], [103, 103, 115], [98, 96, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features labels\n",
       "0   [[[157, 181, 201], [156, 181, 201], [157, 182,...      0\n",
       "1   [[[255, 255, 255], [255, 255, 255], [255, 255,...      0\n",
       "2   [[[85, 91, 104], [87, 95, 108], [82, 94, 106],...      0\n",
       "3   [[[173, 188, 191], [172, 187, 190], [177, 192,...      0\n",
       "4   [[[236, 240, 240], [212, 216, 217], [199, 202,...     10\n",
       "5   [[[197, 199, 200], [197, 199, 200], [197, 199,...      0\n",
       "6   [[[163, 173, 183], [165, 175, 185], [166, 174,...      0\n",
       "7   [[[255, 255, 255], [255, 255, 255], [255, 255,...      0\n",
       "8   [[[242, 251, 248], [242, 251, 248], [240, 249,...      0\n",
       "9   [[[196, 193, 188], [196, 193, 188], [196, 193,...     10\n",
       "10  [[[237, 209, 192], [237, 209, 192], [233, 205,...     10\n",
       "11  [[[11, 6, 12], [11, 7, 13], [11, 7, 13], [8, 7...      5\n",
       "12  [[[255, 255, 255], [255, 255, 255], [255, 255,...     10\n",
       "13  [[[103, 103, 117], [103, 103, 115], [98, 96, 1...      0\n",
       "14  [[[255, 255, 255], [255, 255, 255], [255, 255,...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = np.load('dataset-split/batch-000.npy', allow_pickle=True)\n",
    "data = pd.DataFrame(data_train, columns=['features','labels'])\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.index:\n",
    "    data['features'][i] = data['features'][i].reshape(226, 226, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    data['features'].iloc[i] for i in range(data['features'].size)\n",
    ").size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Get the input data\n",
    "X = np.stack(data['features'].to_numpy())\n",
    "\n",
    "# Normalize\n",
    "X = X / 255.0\n",
    "\n",
    "# Get the labels\n",
    "y = data['labels'].to_numpy()\n",
    "y = y.astype(int)\n",
    "\n",
    "# One-hot encode\n",
    "y = np.vectorize(lambda x: x//5 if x>1 else x)(y)\n",
    "\n",
    "# Subtract the minimum label value to ensure that label values start from 0\n",
    "y = y - np.min(y)\n",
    "\n",
    "# One-hot encode\n",
    "y = to_categorical(y, num_classes=3)\n",
    "\n",
    "y[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 15:02:02.239077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 15:02:02.241100: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Define the Keras model\n",
    "model_cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=X_train[0].shape),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(x) for x in (X_train, y_train, X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "del data_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 73s 35s/step - loss: 1.1037 - accuracy: 0.3333 - val_loss: 1.4907 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 72s 34s/step - loss: 1.2730 - accuracy: 0.2833 - val_loss: 1.1121 - val_accuracy: 0.2667\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 78s 37s/step - loss: 1.0914 - accuracy: 0.2500 - val_loss: 1.1300 - val_accuracy: 0.2667\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 75s 36s/step - loss: 1.0686 - accuracy: 0.4167 - val_loss: 1.1627 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 74s 37s/step - loss: 1.0825 - accuracy: 0.4833 - val_loss: 1.2947 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 72s 35s/step - loss: 0.9668 - accuracy: 0.5667 - val_loss: 1.3015 - val_accuracy: 0.2000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 73s 35s/step - loss: 0.9101 - accuracy: 0.6333 - val_loss: 1.4685 - val_accuracy: 0.1333\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 73s 35s/step - loss: 0.8961 - accuracy: 0.5833 - val_loss: 1.7081 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 72s 35s/step - loss: 0.8130 - accuracy: 0.6500 - val_loss: 1.7868 - val_accuracy: 0.2667\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 72s 35s/step - loss: 0.7733 - accuracy: 0.6500 - val_loss: 1.4382 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e9a0ee460>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final preparation\n",
    "X_train, y_train, X_test, y_test = tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train), tf.convert_to_tensor(X_test), tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import os\n",
    "model_cnn.save(os.path.join(os.getcwd(), 'cnn.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
